{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A hierarchical model\n",
    "\n",
    "Suppose ***scholastic aptitude (SA)***, denoted $u$, is distributed normally in the population with mean $\\mu_0$ and variance $\\sigma_0^2$:\n",
    "$$\n",
    "u\\sim N(\\mu_0, \\sigma_0^2)\n",
    "$$\n",
    "\n",
    "The random variable $u$ is ***latent*** &mdash; unobservable.\n",
    "\n",
    "A person's ***Scholastic Aptitute Test (SAT)*** score, denoted $y$, is supposed to reflect their scholastic aptitute $u$. Assume:\n",
    "$$\n",
    "y\\mid u \\sim N(u, \\sigma^2)\n",
    "$$\n",
    "Thus, $\\sigma$ is a reflection of the SAT's measurement error.\n",
    "\n",
    "Variance in SAT score in the population has two sources: variation in SA across the population ($\\sigma_0$) and variation in SAT scores among people with the same SA ($\\sigma$). By *The Theory*, these two sources of variation combine additively:\n",
    "$$\n",
    "y\\sim N(\\mu_0,\\sigma_0^2 + \\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An application of Bayes' Theorem\n",
    "\n",
    "What can we say about someone's SA if we know their test score? More precisely, what is $p(u\\mid y)$?\n",
    "\n",
    "By Bayes' Theorem,\n",
    "$$\n",
    "p(u\\mid y) = \\frac{p(y\\mid u)p(u)}{p(y)}.\n",
    "$$\n",
    "\n",
    "We know $p(u)$, $p(y\\mid u)$, and $p(y)$. With some algebraic perseverance, we manipulate the right hand side of the the above identify into standard Gaussian form and identify its mean and variance.\n",
    "\n",
    "Set\n",
    "$$\n",
    "\\tau_0 = \\frac1{\\sigma_0},\\qquad \\tau= \\frac1{\\sigma}.\n",
    "$$\n",
    "The reciprocal variances $\\tau_0^2$ and $\\tau$^2 are called ***precisions***.\n",
    "\n",
    "We have:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[u\\mid y] &= \\frac{\\tau_0^2}{\\tau_0^2 + \\tau^2}\\mu_0 + \\frac{\\tau^2}{\\tau_0^2 + \\tau^2}y\\\\\n",
    "\\mathbb{V}[u\\mid y] &= \\frac{1}{\\tau_0^2 + \\tau^2}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\theta$ be the ratio of uncertainty in scholastic aptitude to uncertainty in SAT results.\n",
    "$$\n",
    "\\theta = \\frac{\\sigma_0}{\\sigma} = \\frac{\\tau}{\\tau_0}.\n",
    "$$\n",
    "(The larger $\\theta$ is, the more reliable the SAT for capturing the latent SA quantity.)\n",
    "\n",
    "Setting\n",
    "$$\n",
    "t = \\frac{1}{1 + \\theta^2}\n",
    "$$\n",
    "we have\n",
    "$$\n",
    "\\mathbb{E}[u\\mid y] = t\\mu_0 + (1 - t)y.\n",
    "$$\n",
    "\n",
    "The expression on the right hand side lies between $\\mu_0$ and $y$.\n",
    "\n",
    "If $\\theta$ is small, $\\mathbb{E}[u\\mid y]$ is close to $\\mu_0$. Makes sense: If $\\theta$ is small then the SAT score $y$ isn't a reliable reflection of SA $u$ we hedge our bet for $u$ towards the population mean.\n",
    "\n",
    "If $\\theta$ is big, $\\mathbb{E}[u\\mid y]$ is close to $y$. Makes sense: If $\\theta$ is big then the SAT score $y$ is a reliable reflection of SA $u$ and we don't need to hedge our bets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More generally\n",
    "\n",
    "You might draw many $y$ subordinate to the same draw of $u$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "u_i&\\sim N(\\mu_0, \\sigma_0^2),&&i<m,\\\\\n",
    "y_{ij}\\mid u_i &\\sim N(u_i,\\sigma^2),&&j < n_i\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Two draws $y_{ij}$ and $y_{ij'}$ are identically distributed and conditionally independent, given $u_i$, but not independent.\n",
    "\n",
    "Later, we'll discuss how to estimate the parameters of such a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>i</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.690121</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.086729</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.626803</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.398956</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.576059</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y  i  Intercept\n",
       "0  22.690121  2          1\n",
       "1  23.086729  5          1\n",
       "2  26.626803  4          1\n",
       "3  31.398956  0          1\n",
       "4  23.576059  3          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.api import MixedLM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "mu0 = 20\n",
    "sigma0 = 5\n",
    "sigma = 3\n",
    "m = 7\n",
    "\n",
    "cat_dtype = pd.CategoricalDtype(categories=np.arange(m))\n",
    "\n",
    "\n",
    "def make_data(n, rng=None):\n",
    "    rng = np.random.default_rng(rng)\n",
    "    u = rng.normal(mu0, sigma0, size=m)\n",
    "    i = rng.choice(range(m), size=n)\n",
    "    y = rng.normal(u[i], sigma)\n",
    "    df = pd.DataFrame({\"y\": y, \"i\": i, \"Intercept\": 1})\n",
    "    df[\"i\"] = df[\"i\"].astype(cat_dtype)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = make_data(30)\n",
    "df_test = make_data(10_000)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.53576270112236"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train[\"y\"]\n",
    "X_train = pd.get_dummies(df_train[\"i\"])\n",
    "assert X_train.shape[1] == 7\n",
    "\n",
    "y_test = df_test[\"y\"]\n",
    "X_test = pd.get_dummies(df_test[\"i\"])\n",
    "assert X_train.shape[1] == 7\n",
    "\n",
    "lr_model = LinearRegression(fit_intercept=False)\n",
    "lr_model.fit(X_train, y_train)\n",
    "test_mse = mean_squared_error(y_test, lr_model.predict(X_test))\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>     <td>y</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>   <td>30</td>          <td>Method:</td>         <td>REML</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>       <td>7</td>          <td>Scale:</td>         <td>8.0804</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>     <td>2</td>      <td>Log-Likelihood:</td>   <td>-82.3855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>     <td>9</td>        <td>Converged:</td>         <td>Yes</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>    <td>4.3</td>            <td></td>               <td></td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th> <th>Std.Err.</th>   <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>21.420</td>   <td>2.647</td>  <td>8.093</td> <td>0.000</td> <td>16.232</td> <td>26.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group Var</th> <td>46.552</td>  <td>11.252</td>    <td></td>      <td></td>       <td></td>       <td></td>   \n",
       "</tr>\n",
       "</table><br/>\n"
      ],
      "text/latex": [
       "\\begin{table}\n",
       "\\caption{Mixed Linear Model Regression Results}\n",
       "\\label{}\n",
       "\\begin{center}\n",
       "\\begin{tabular}{llll}\n",
       "\\hline\n",
       "Model:            & MixedLM & Dependent Variable: & y         \\\\\n",
       "No. Observations: & 30      & Method:             & REML      \\\\\n",
       "No. Groups:       & 7       & Scale:              & 8.0804    \\\\\n",
       "Min. group size:  & 2       & Log-Likelihood:     & -82.3855  \\\\\n",
       "Max. group size:  & 9       & Converged:          & Yes       \\\\\n",
       "Mean group size:  & 4.3     &                     &           \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\n",
       "\\begin{center}\n",
       "\\begin{tabular}{lrrrrrr}\n",
       "\\hline\n",
       "          &  Coef. & Std.Err. &     z & P$> |$z$|$ & [0.025 & 0.975]  \\\\\n",
       "\\hline\n",
       "Intercept & 21.420 &    2.647 & 8.093 &       0.000 & 16.232 & 26.607  \\\\\n",
       "Group Var & 46.552 &   11.252 &       &             &        &         \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\\end{table}\n",
       "\\bigskip\n"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "        Mixed Linear Model Regression Results\n",
       "======================================================\n",
       "Model:            MixedLM Dependent Variable: y       \n",
       "No. Observations: 30      Method:             REML    \n",
       "No. Groups:       7       Scale:              8.0804  \n",
       "Min. group size:  2       Log-Likelihood:     -82.3855\n",
       "Max. group size:  9       Converged:          Yes     \n",
       "Mean group size:  4.3                                 \n",
       "------------------------------------------------------\n",
       "             Coef.  Std.Err.   z   P>|z| [0.025 0.975]\n",
       "------------------------------------------------------\n",
       "Intercept    21.420    2.647 8.093 0.000 16.232 26.607\n",
       "Group Var    46.552   11.252                          \n",
       "======================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_model = MixedLM(df_train[\"y\"], df_train[[\"Intercept\"]], groups=df_train[\"i\"])\n",
    "fit = mixed_model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(df_train.groupby(\"i\", observed=False)[\"y\"].mean(), lr_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.46394645787881"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_preds = fit.params[\"Intercept\"] + df_test[\"i\"].map(\n",
    "    lambda i: fit.random_effects[i][\"Group Var\"]\n",
    ").astype(float)\n",
    "test_mse = mean_squared_error(y_test, mixed_preds)\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2206: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2218: ConvergenceWarning: Gradient optimization failed, |grad| = 0.621835\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2206: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2218: ConvergenceWarning: Gradient optimization failed, |grad| = 1.775420\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2206: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2218: ConvergenceWarning: Gradient optimization failed, |grad| = 0.487533\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2206: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2218: ConvergenceWarning: Gradient optimization failed, |grad| = 1.257352\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2206: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2218: ConvergenceWarning: Gradient optimization failed, |grad| = 1.312430\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:1634: UserWarning: Random effects covariance is singular\n",
      "  warnings.warn(msg)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2200: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/mgreenbe/DATA335W2025/.venv/lib/python3.12/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "fe_mses = []\n",
    "re_mses = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    df_train = make_data(30)\n",
    "    y_train = df_train[\"y\"]\n",
    "    X_train = pd.get_dummies(df_train[\"i\"])\n",
    "    assert X_train.shape[1] == 7\n",
    "\n",
    "    y_test = df_test[\"y\"]\n",
    "    X_test = pd.get_dummies(df_test[\"i\"])\n",
    "    assert X_train.shape[1] == 7\n",
    "\n",
    "    lr_model = LinearRegression(fit_intercept=False)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    assert np.allclose(\n",
    "        df_train.groupby(\"i\", observed=False)[\"y\"].mean().fillna(0.0), lr_model.coef_\n",
    "    )\n",
    "    fe_mse = mean_squared_error(y_test, lr_model.predict(X_test))\n",
    "    fe_mses.append(fe_mse)\n",
    "\n",
    "    mixed_model = MixedLM(df_train[\"y\"], df_train[[\"Intercept\"]], groups=df_train[\"i\"])\n",
    "    fit = mixed_model.fit()\n",
    "\n",
    "    mixed_preds = fit.params[\"Intercept\"] + df_test[\"i\"].map(\n",
    "        lambda i: fit.random_effects[i][\"Group Var\"] if i in fit.random_effects else 0.0\n",
    "    ).astype(float)\n",
    "    re_mse = mean_squared_error(y_test, mixed_preds)\n",
    "    re_mses.append(re_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, bins, __ = plt.hist(fe_mses, bins=20, alpha=0.5, label=\"fixed effects model\")\n",
    "plt.hist(re_mses, bins=bins, alpha=0.5, label=\"random effects model\")\n",
    "plt.vlines([np.mean(fe_mses), np.mean(re_mses)], *plt.ylim(), colors=[\"C0\", \"C1\"])\n",
    "plt.title(\"Distribution of test set MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnum</th>\n",
       "      <th>state</th>\n",
       "      <th>state2</th>\n",
       "      <th>stfips</th>\n",
       "      <th>zip</th>\n",
       "      <th>region</th>\n",
       "      <th>typebldg</th>\n",
       "      <th>floor</th>\n",
       "      <th>room</th>\n",
       "      <th>basement</th>\n",
       "      <th>...</th>\n",
       "      <th>stoptm</th>\n",
       "      <th>startdt</th>\n",
       "      <th>stopdt</th>\n",
       "      <th>activity</th>\n",
       "      <th>pcterr</th>\n",
       "      <th>adjwt</th>\n",
       "      <th>dupflag</th>\n",
       "      <th>zipflag</th>\n",
       "      <th>cntyfips</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>5081</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55735</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>930</td>\n",
       "      <td>12088</td>\n",
       "      <td>12288</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1146.499190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>5082</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55748</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>1615</td>\n",
       "      <td>11888</td>\n",
       "      <td>12088</td>\n",
       "      <td>2.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>471.366223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5082</th>\n",
       "      <td>5083</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55748</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>1515</td>\n",
       "      <td>20288</td>\n",
       "      <td>21188</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>433.316718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5083</th>\n",
       "      <td>5084</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>56469</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>1410</td>\n",
       "      <td>122987</td>\n",
       "      <td>123187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>461.623670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>5085</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55011</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>600</td>\n",
       "      <td>12888</td>\n",
       "      <td>13088</td>\n",
       "      <td>3.1</td>\n",
       "      <td>13.8</td>\n",
       "      <td>433.316718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ANOKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>5995</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55363</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>1730</td>\n",
       "      <td>122687</td>\n",
       "      <td>122887</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1146.499190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>WRIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5996</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55376</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>700</td>\n",
       "      <td>121787</td>\n",
       "      <td>121987</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1105.956867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>WRIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5997</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55376</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>1045</td>\n",
       "      <td>12888</td>\n",
       "      <td>13088</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1214.922779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>WRIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5998</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>56297</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>940</td>\n",
       "      <td>122887</td>\n",
       "      <td>123087</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1177.377355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>YELLOW MEDICINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>5999</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>56297</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>800</td>\n",
       "      <td>21088</td>\n",
       "      <td>21388</td>\n",
       "      <td>2.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1214.922779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>YELLOW MEDICINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>919 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idnum state state2  stfips    zip  region  typebldg  floor  room  \\\n",
       "5080   5081    MN     MN      27  55735       5         1      1     3   \n",
       "5081   5082    MN     MN      27  55748       5         1      0     4   \n",
       "5082   5083    MN     MN      27  55748       5         1      0     4   \n",
       "5083   5084    MN     MN      27  56469       5         1      0     4   \n",
       "5084   5085    MN     MN      27  55011       3         1      0     4   \n",
       "...     ...   ...    ...     ...    ...     ...       ...    ...   ...   \n",
       "5994   5995    MN     MN      27  55363       5         1      0     4   \n",
       "5995   5996    MN     MN      27  55376       5         1      0     7   \n",
       "5996   5997    MN     MN      27  55376       5         1      0     4   \n",
       "5997   5998    MN     MN      27  56297       5         1      0     4   \n",
       "5998   5999    MN     MN      27  56297       5         1      0     4   \n",
       "\n",
       "     basement  ... stoptm startdt  stopdt activity  pcterr        adjwt  \\\n",
       "5080        N  ...    930   12088   12288      2.2     9.7  1146.499190   \n",
       "5081        Y  ...   1615   11888   12088      2.2    14.5   471.366223   \n",
       "5082        Y  ...   1515   20288   21188      2.9     9.6   433.316718   \n",
       "5083        Y  ...   1410  122987  123187      1.0    24.3   461.623670   \n",
       "5084        Y  ...    600   12888   13088      3.1    13.8   433.316718   \n",
       "...       ...  ...    ...     ...     ...      ...     ...          ...   \n",
       "5994        Y  ...   1730  122687  122887      6.4     4.5  1146.499190   \n",
       "5995        Y  ...    700  121787  121987      4.5     8.3  1105.956867   \n",
       "5996        Y  ...   1045   12888   13088      5.0     5.2  1214.922779   \n",
       "5997        Y  ...    940  122887  123087      3.7     9.6  1177.377355   \n",
       "5998        Y  ...    800   21088   21388      2.9     8.0  1214.922779   \n",
       "\n",
       "      dupflag  zipflag  cntyfips                county  \n",
       "5080        1        0         1  AITKIN                \n",
       "5081        0        0         1  AITKIN                \n",
       "5082        0        0         1  AITKIN                \n",
       "5083        0        0         1  AITKIN                \n",
       "5084        0        0         3  ANOKA                 \n",
       "...       ...      ...       ...                   ...  \n",
       "5994        0        0       171  WRIGHT                \n",
       "5995        0        0       171  WRIGHT                \n",
       "5996        0        0       171  WRIGHT                \n",
       "5997        0        0       173  YELLOW MEDICINE       \n",
       "5998        0        0       173  YELLOW MEDICINE       \n",
       "\n",
       "[919 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get radon data\n",
    "path = \"https://raw.githubusercontent.com/pymc-devs/pymc-examples/main/examples/data/srrs2.dat\"\n",
    "radon_df = pd.read_csv(path)\n",
    "\n",
    "# Strip spaces from column names\n",
    "radon_df.columns = radon_df.columns.map(str.strip)\n",
    "\n",
    "# Filter to keep observations for \"MN\" state only\n",
    "radon_df = radon_df[radon_df.state == \"MN\"].copy()\n",
    "\n",
    "radon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5080    27001\n",
       "5081    27001\n",
       "5082    27001\n",
       "5083    27001\n",
       "5084    27003\n",
       "        ...  \n",
       "5994    27171\n",
       "5995    27171\n",
       "5996    27171\n",
       "5997    27173\n",
       "5998    27173\n",
       "Name: fips, Length: 919, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a FIPS column\n",
    "radon_df[\"fips\"] = 1_000 * radon_df.stfips + radon_df.cntyfips\n",
    "radon_df[\"fips\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stfips</th>\n",
       "      <th>ctfips</th>\n",
       "      <th>st</th>\n",
       "      <th>cty</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>Uppm</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>-86.643</td>\n",
       "      <td>32.534</td>\n",
       "      <td>1.78331</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>AL</td>\n",
       "      <td>BALDWIN</td>\n",
       "      <td>-87.750</td>\n",
       "      <td>30.661</td>\n",
       "      <td>1.38323</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>BARBOUR</td>\n",
       "      <td>-85.393</td>\n",
       "      <td>31.870</td>\n",
       "      <td>2.10105</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>AL</td>\n",
       "      <td>BIBB</td>\n",
       "      <td>-87.126</td>\n",
       "      <td>32.998</td>\n",
       "      <td>1.67313</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>AL</td>\n",
       "      <td>BLOUNT</td>\n",
       "      <td>-86.568</td>\n",
       "      <td>33.981</td>\n",
       "      <td>1.88501</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>WY</td>\n",
       "      <td>SWEETWATER</td>\n",
       "      <td>-108.879</td>\n",
       "      <td>41.660</td>\n",
       "      <td>2.42132</td>\n",
       "      <td>56037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>WY</td>\n",
       "      <td>TETON</td>\n",
       "      <td>-110.589</td>\n",
       "      <td>43.934</td>\n",
       "      <td>2.39226</td>\n",
       "      <td>56039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>WY</td>\n",
       "      <td>UINTA</td>\n",
       "      <td>-110.547</td>\n",
       "      <td>41.288</td>\n",
       "      <td>2.31204</td>\n",
       "      <td>56041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>WY</td>\n",
       "      <td>WASHAKIE</td>\n",
       "      <td>-107.682</td>\n",
       "      <td>43.905</td>\n",
       "      <td>2.63989</td>\n",
       "      <td>56043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>WY</td>\n",
       "      <td>WESTON</td>\n",
       "      <td>-104.567</td>\n",
       "      <td>43.841</td>\n",
       "      <td>2.18167</td>\n",
       "      <td>56045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3194 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stfips  ctfips  st         cty      lon     lat     Uppm   fips\n",
       "0          1       1  AL     AUTAUGA  -86.643  32.534  1.78331   1001\n",
       "1          1       3  AL     BALDWIN  -87.750  30.661  1.38323   1003\n",
       "2          1       5  AL     BARBOUR  -85.393  31.870  2.10105   1005\n",
       "3          1       7  AL        BIBB  -87.126  32.998  1.67313   1007\n",
       "4          1       9  AL      BLOUNT  -86.568  33.981  1.88501   1009\n",
       "...      ...     ...  ..         ...      ...     ...      ...    ...\n",
       "3189      56      37  WY  SWEETWATER -108.879  41.660  2.42132  56037\n",
       "3190      56      39  WY       TETON -110.589  43.934  2.39226  56039\n",
       "3191      56      41  WY       UINTA -110.547  41.288  2.31204  56041\n",
       "3192      56      43  WY    WASHAKIE -107.682  43.905  2.63989  56043\n",
       "3193      56      45  WY      WESTON -104.567  43.841  2.18167  56045\n",
       "\n",
       "[3194 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc as pm\n",
    "\n",
    "# Get city data\n",
    "city_df = pd.read_csv(pm.get_data(\"cty.dat\"))\n",
    "\n",
    "# Add FIPS column\n",
    "city_df[\"fips\"] = 1_000 * city_df.stfips + city_df.ctfips\n",
    "\n",
    "city_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnum</th>\n",
       "      <th>state</th>\n",
       "      <th>state2</th>\n",
       "      <th>stfips</th>\n",
       "      <th>zip</th>\n",
       "      <th>region</th>\n",
       "      <th>typebldg</th>\n",
       "      <th>floor</th>\n",
       "      <th>room</th>\n",
       "      <th>basement</th>\n",
       "      <th>...</th>\n",
       "      <th>activity</th>\n",
       "      <th>pcterr</th>\n",
       "      <th>adjwt</th>\n",
       "      <th>dupflag</th>\n",
       "      <th>zipflag</th>\n",
       "      <th>cntyfips</th>\n",
       "      <th>county</th>\n",
       "      <th>fips</th>\n",
       "      <th>Uppm</th>\n",
       "      <th>log_radon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5540</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>56031</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Basement</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1177.377355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>27091</td>\n",
       "      <td>1.180410</td>\n",
       "      <td>1.435085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5665</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55110</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Basement</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2314.365189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>RAMSEY</td>\n",
       "      <td>27123</td>\n",
       "      <td>0.658327</td>\n",
       "      <td>1.029619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5666</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55112</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Basement</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>2116.561544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>RAMSEY</td>\n",
       "      <td>27123</td>\n",
       "      <td>0.658327</td>\n",
       "      <td>0.262364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5667</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55112</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Basement</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2116.561544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>RAMSEY</td>\n",
       "      <td>27123</td>\n",
       "      <td>0.658327</td>\n",
       "      <td>1.280934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5668</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55113</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Basement</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2179.503255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>RAMSEY</td>\n",
       "      <td>27123</td>\n",
       "      <td>0.658327</td>\n",
       "      <td>1.722767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>5757</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55731</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Floor</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>29.7</td>\n",
       "      <td>461.274696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>ST LOUIS</td>\n",
       "      <td>27137</td>\n",
       "      <td>0.622088</td>\n",
       "      <td>-0.510826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>5759</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55732</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Floor</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>461.274696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>ST LOUIS</td>\n",
       "      <td>27137</td>\n",
       "      <td>0.622088</td>\n",
       "      <td>0.530628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>5765</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55741</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Floor</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>35.3</td>\n",
       "      <td>461.623670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>ST LOUIS</td>\n",
       "      <td>27137</td>\n",
       "      <td>0.622088</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>5718</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55044</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Floor</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>461.274696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>SCOTT</td>\n",
       "      <td>27139</td>\n",
       "      <td>1.065150</td>\n",
       "      <td>2.219203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>5081</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "      <td>27</td>\n",
       "      <td>55735</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Floor</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1146.499190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.502054</td>\n",
       "      <td>0.832909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>919 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idnum state state2  stfips    zip  region  typebldg     floor  room  \\\n",
       "0     5540    MN     MN      27  56031       5         1  Basement     4   \n",
       "1     5665    MN     MN      27  55110       3         1  Basement     4   \n",
       "2     5666    MN     MN      27  55112       3         1  Basement     4   \n",
       "3     5667    MN     MN      27  55112       3         1  Basement     2   \n",
       "4     5668    MN     MN      27  55113       3         1  Basement     2   \n",
       "..     ...   ...    ...     ...    ...     ...       ...       ...   ...   \n",
       "914   5757    MN     MN      27  55731       1         1     Floor     3   \n",
       "915   5759    MN     MN      27  55732       1         1     Floor     1   \n",
       "916   5765    MN     MN      27  55741       1         1     Floor     3   \n",
       "917   5718    MN     MN      27  55044       5         1     Floor     1   \n",
       "918   5081    MN     MN      27  55735       5         1     Floor     3   \n",
       "\n",
       "    basement  ... activity pcterr        adjwt dupflag  zipflag  cntyfips  \\\n",
       "0          Y  ...      4.1    5.6  1177.377355       0        0        91   \n",
       "1          Y  ...      2.7   11.0  2314.365189       0        0       123   \n",
       "2          Y  ...      1.2   16.7  2116.561544       0        0       123   \n",
       "3          Y  ...      3.5    6.5  2116.561544       0        0       123   \n",
       "4          Y  ...      5.5    5.3  2179.503255       0        0       123   \n",
       "..       ...  ...      ...    ...          ...     ...      ...       ...   \n",
       "914        Y  ...      0.5   29.7   461.274696       0        0       137   \n",
       "915        Y  ...      1.6   11.3   461.274696       0        0       137   \n",
       "916        Y  ...      0.9   35.3   461.623670       0        0       137   \n",
       "917        N  ...      9.1    3.7   461.274696       0        0       139   \n",
       "918        N  ...      2.2    9.7  1146.499190       1        0         1   \n",
       "\n",
       "       county   fips      Uppm  log_radon  \n",
       "0      MARTIN  27091  1.180410   1.435085  \n",
       "1      RAMSEY  27123  0.658327   1.029619  \n",
       "2      RAMSEY  27123  0.658327   0.262364  \n",
       "3      RAMSEY  27123  0.658327   1.280934  \n",
       "4      RAMSEY  27123  0.658327   1.722767  \n",
       "..        ...    ...       ...        ...  \n",
       "914  ST LOUIS  27137  0.622088  -0.510826  \n",
       "915  ST LOUIS  27137  0.622088   0.530628  \n",
       "916  ST LOUIS  27137  0.622088   0.000000  \n",
       "917     SCOTT  27139  1.065150   2.219203  \n",
       "918    AITKIN  27001  0.502054   0.832909  \n",
       "\n",
       "[919 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data\n",
    "df = radon_df.merge(city_df[[\"fips\", \"Uppm\"]], on=\"fips\", how=\"left\")\n",
    "df = df.drop_duplicates(subset=\"idnum\")\n",
    "\n",
    "# Clean county names\n",
    "df.county = df.county.map(str.strip)\n",
    "\n",
    "# Compute log(radon + 0.1)\n",
    "df[\"log_radon\"] = np.log(df[\"activity\"] + 0.1)\n",
    "\n",
    "# Let's map floor 0 -> \"Basement\" and floor 1 -> \"Floor\"\n",
    "df[\"floor\"] = df[\"floor\"].map({0: \"Basement\", 1: \"Floor\"})\n",
    "\n",
    "# Sort values by floor\n",
    "df = df.sort_values(by=\"floor\")\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df.loc[df[\"floor\"] == \"Basement\", [\"log_radon\", \"county\"]]\n",
    "small_df[\"Intercept\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td> <td>log_radon</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>   <td>766</td>         <td>Method:</td>         <td>REML</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>85</td>          <td>Scale:</td>         <td>0.4527</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>     <td>1</td>      <td>Log-Likelihood:</td>   <td>-824.0279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>100</td>       <td>Converged:</td>         <td>Yes</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>    <td>9.0</td>            <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>      <th>Coef.</th> <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>1.494</td>   <td>0.053</td>  <td>28.377</td> <td>0.000</td>  <td>1.391</td>  <td>1.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group Var</th> <td>0.125</td>   <td>0.052</td>     <td></td>      <td></td>       <td></td>       <td></td>   \n",
       "</tr>\n",
       "</table><br/>\n"
      ],
      "text/latex": [
       "\\begin{table}\n",
       "\\caption{Mixed Linear Model Regression Results}\n",
       "\\label{}\n",
       "\\begin{center}\n",
       "\\begin{tabular}{llll}\n",
       "\\hline\n",
       "Model:            & MixedLM & Dependent Variable: & log\\_radon  \\\\\n",
       "No. Observations: & 766     & Method:             & REML        \\\\\n",
       "No. Groups:       & 85      & Scale:              & 0.4527      \\\\\n",
       "Min. group size:  & 1       & Log-Likelihood:     & -824.0279   \\\\\n",
       "Max. group size:  & 100     & Converged:          & Yes         \\\\\n",
       "Mean group size:  & 9.0     &                     &             \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\n",
       "\\begin{center}\n",
       "\\begin{tabular}{lrrrrrr}\n",
       "\\hline\n",
       "          & Coef. & Std.Err. &      z & P$> |$z$|$ & [0.025 & 0.975]  \\\\\n",
       "\\hline\n",
       "Intercept & 1.494 &    0.053 & 28.377 &       0.000 &  1.391 &  1.597  \\\\\n",
       "Group Var & 0.125 &    0.052 &        &             &        &         \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\\end{table}\n",
       "\\bigskip\n"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "         Mixed Linear Model Regression Results\n",
       "=======================================================\n",
       "Model:            MixedLM Dependent Variable: log_radon\n",
       "No. Observations: 766     Method:             REML     \n",
       "No. Groups:       85      Scale:              0.4527   \n",
       "Min. group size:  1       Log-Likelihood:     -824.0279\n",
       "Max. group size:  100     Converged:          Yes      \n",
       "Mean group size:  9.0                                  \n",
       "-------------------------------------------------------\n",
       "              Coef. Std.Err.   z    P>|z| [0.025 0.975]\n",
       "-------------------------------------------------------\n",
       "Intercept     1.494    0.053 28.377 0.000  1.391  1.597\n",
       "Group Var     0.125    0.052                           \n",
       "=======================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_model = MixedLM(\n",
    "    small_df[\"log_radon\"], small_df[[\"Intercept\"]], groups=small_df[\"county\"]\n",
    ")\n",
    "fit = mixed_model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AITKIN': Group Var   -0.370765\n",
       " dtype: float64,\n",
       " 'ANOKA': Group Var   -0.503776\n",
       " dtype: float64,\n",
       " 'BECKER': Group Var   -0.002718\n",
       " dtype: float64,\n",
       " 'BELTRAMI': Group Var    0.102549\n",
       " dtype: float64,\n",
       " 'BENTON': Group Var   -0.06827\n",
       " dtype: float64,\n",
       " 'BIG STONE': Group Var    0.019305\n",
       " dtype: float64,\n",
       " 'BLUE EARTH': Group Var    0.29428\n",
       " dtype: float64,\n",
       " 'BROWN': Group Var    0.222464\n",
       " dtype: float64,\n",
       " 'CARLTON': Group Var   -0.4294\n",
       " dtype: float64,\n",
       " 'CARVER': Group Var    0.13365\n",
       " dtype: float64,\n",
       " 'CASS': Group Var   -0.038316\n",
       " dtype: float64,\n",
       " 'CHIPPEWA': Group Var    0.137309\n",
       " dtype: float64,\n",
       " 'CHISAGO': Group Var   -0.255285\n",
       " dtype: float64,\n",
       " 'CLAY': Group Var    0.455265\n",
       " dtype: float64,\n",
       " 'CLEARWATER': Group Var   -0.08586\n",
       " dtype: float64,\n",
       " 'COOK': Group Var   -0.276219\n",
       " dtype: float64,\n",
       " 'COTTONWOOD': Group Var    0.094598\n",
       " dtype: float64,\n",
       " 'CROW WING': Group Var   -0.361467\n",
       " dtype: float64,\n",
       " 'DAKOTA': Group Var   -0.102646\n",
       " dtype: float64,\n",
       " 'DODGE': Group Var    0.146147\n",
       " dtype: float64,\n",
       " 'DOUGLAS': Group Var    0.152921\n",
       " dtype: float64,\n",
       " 'FARIBAULT': Group Var   -0.443652\n",
       " dtype: float64,\n",
       " 'FILLMORE': Group Var   -0.064942\n",
       " dtype: float64,\n",
       " 'FREEBORN': Group Var    0.433501\n",
       " dtype: float64,\n",
       " 'GOODHUE': Group Var    0.253493\n",
       " dtype: float64,\n",
       " 'HENNEPIN': Group Var   -0.086774\n",
       " dtype: float64,\n",
       " 'HOUSTON': Group Var    0.123891\n",
       " dtype: float64,\n",
       " 'HUBBARD': Group Var   -0.172635\n",
       " dtype: float64,\n",
       " 'ISANTI': Group Var   -0.182669\n",
       " dtype: float64,\n",
       " 'ITASCA': Group Var   -0.394377\n",
       " dtype: float64,\n",
       " 'JACKSON': Group Var    0.314458\n",
       " dtype: float64,\n",
       " 'KANABEC': Group Var   -0.118211\n",
       " dtype: float64,\n",
       " 'KANDIYOHI': Group Var    0.305203\n",
       " dtype: float64,\n",
       " 'KITTSON': Group Var    0.09771\n",
       " dtype: float64,\n",
       " 'KOOCHICHING': Group Var   -0.512428\n",
       " dtype: float64,\n",
       " 'LAC QUI PARLE': Group Var    0.277866\n",
       " dtype: float64,\n",
       " 'LAKE': Group Var   -0.739818\n",
       " dtype: float64,\n",
       " 'LAKE OF THE WOODS': Group Var    0.099199\n",
       " dtype: float64,\n",
       " 'LE SUEUR': Group Var    0.090925\n",
       " dtype: float64,\n",
       " 'LINCOLN': Group Var    0.428048\n",
       " dtype: float64,\n",
       " 'LYON': Group Var    0.25775\n",
       " dtype: float64,\n",
       " 'MAHNOMEN': Group Var   -0.023333\n",
       " dtype: float64,\n",
       " 'MARSHALL': Group Var    0.559809\n",
       " dtype: float64,\n",
       " 'MARTIN': Group Var   -0.14503\n",
       " dtype: float64,\n",
       " 'MCLEOD': Group Var   -0.055304\n",
       " dtype: float64,\n",
       " 'MEEKER': Group Var   -0.143661\n",
       " dtype: float64,\n",
       " 'MILLE LACS': Group Var    0.057035\n",
       " dtype: float64,\n",
       " 'MORRISON': Group Var   -0.270769\n",
       " dtype: float64,\n",
       " 'MOWER': Group Var    0.281417\n",
       " dtype: float64,\n",
       " 'MURRAY': Group Var    0.217869\n",
       " dtype: float64,\n",
       " 'NICOLLET': Group Var    0.35875\n",
       " dtype: float64,\n",
       " 'NOBLES': Group Var    0.203098\n",
       " dtype: float64,\n",
       " 'NORMAN': Group Var   -0.062877\n",
       " dtype: float64,\n",
       " 'OLMSTED': Group Var   -0.064277\n",
       " dtype: float64,\n",
       " 'OTTER TAIL': Group Var    0.007595\n",
       " dtype: float64,\n",
       " 'PENNINGTON': Group Var    0.060733\n",
       " dtype: float64,\n",
       " 'PINE': Group Var   -0.411159\n",
       " dtype: float64,\n",
       " 'PIPESTONE': Group Var    0.129544\n",
       " dtype: float64,\n",
       " 'POLK': Group Var    0.21868\n",
       " dtype: float64,\n",
       " 'POPE': Group Var   -0.066616\n",
       " dtype: float64,\n",
       " 'RAMSEY': Group Var   -0.338074\n",
       " dtype: float64,\n",
       " 'REDWOOD': Group Var    0.037986\n",
       " dtype: float64,\n",
       " 'RENVILLE': Group Var   -0.069638\n",
       " dtype: float64,\n",
       " 'RICE': Group Var    0.29047\n",
       " dtype: float64,\n",
       " 'ROCK': Group Var   -0.056487\n",
       " dtype: float64,\n",
       " 'ROSEAU': Group Var    0.075986\n",
       " dtype: float64,\n",
       " 'SCOTT': Group Var    0.061415\n",
       " dtype: float64,\n",
       " 'SHERBURNE': Group Var   -0.254032\n",
       " dtype: float64,\n",
       " 'SIBLEY': Group Var   -0.11507\n",
       " dtype: float64,\n",
       " 'ST LOUIS': Group Var   -0.572773\n",
       " dtype: float64,\n",
       " 'STEARNS': Group Var    0.057968\n",
       " dtype: float64,\n",
       " 'STEELE': Group Var    0.080605\n",
       " dtype: float64,\n",
       " 'STEVENS': Group Var    0.11196\n",
       " dtype: float64,\n",
       " 'SWIFT': Group Var   -0.245268\n",
       " dtype: float64,\n",
       " 'TODD': Group Var   -0.047723\n",
       " dtype: float64,\n",
       " 'TRAVERSE': Group Var    0.273381\n",
       " dtype: float64,\n",
       " 'WABASHA': Group Var    0.318121\n",
       " dtype: float64,\n",
       " 'WADENA': Group Var   -0.034129\n",
       " dtype: float64,\n",
       " 'WASECA': Group Var   -0.354381\n",
       " dtype: float64,\n",
       " 'WASHINGTON': Group Var   -0.08861\n",
       " dtype: float64,\n",
       " 'WATONWAN': Group Var    0.246086\n",
       " dtype: float64,\n",
       " 'WILKIN': Group Var    0.161475\n",
       " dtype: float64,\n",
       " 'WINONA': Group Var    0.338712\n",
       " dtype: float64,\n",
       " 'WRIGHT': Group Var    0.138857\n",
       " dtype: float64,\n",
       " 'YELLOW MEDICINE': Group Var   -0.098648\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.random_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.county = small_df.county.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5664812149785614, 0.4886071084975952)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.api import OLS, MixedLM\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "cv = RepeatedKFold()\n",
    "fe_mses = []\n",
    "re_mses = []\n",
    "for train, test in cv.split(small_df):\n",
    "    y_train = small_df.loc[train, \"log_radon\"]\n",
    "    X_train = small_df.loc[train, [\"Intercept\"]]\n",
    "    groups_train = small_df.loc[train, \"county\"]\n",
    "\n",
    "    y_test = small_df.loc[test, \"log_radon\"]\n",
    "    X_test = small_df.loc[test, [\"Intercept\"]]\n",
    "    groups_test = small_df.loc[test, \"county\"]\n",
    "\n",
    "    fe_fit = OLS(y_train, X_train).fit()\n",
    "    fe_pred = fe_fit.predict(X_test)\n",
    "    fe_mse = mean_squared_error(y_test, fe_pred)\n",
    "    fe_mses.append(fe_mse)\n",
    "\n",
    "    re_fit = MixedLM(y_train, X_train, groups=groups_train).fit()\n",
    "    a = re_fit.params[\"Intercept\"]\n",
    "    res = defaultdict(\n",
    "        lambda: 0.0,\n",
    "        {\n",
    "            county: re_fit.random_effects[county][\"Group Var\"]\n",
    "            for county in re_fit.random_effects\n",
    "        },\n",
    "    )\n",
    "    re_pred = re_fit.params[\"Intercept\"] + groups_test.map(res).astype(float)\n",
    "    re_mse = mean_squared_error(y_test, re_pred)\n",
    "    re_mses.append(re_mse)\n",
    "\n",
    "np.mean(fe_mses), np.mean(re_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
