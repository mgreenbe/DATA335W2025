{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 335 - Winter 2025 - Lab 5\n",
    "\n",
    "2025.02.25, 14:00-15:50, MS 521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset selection, transformers, pipelines, and grid search\n",
    "\n",
    "In this exercise, we use the `data/auto_preprocessed.csv` dataset. Let `X` be the matrix of numerical (non-binary) features and let the target vector `y` be the `mpg` column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv(\"../data/auto_preprocessed.csv\")\n",
    "numerical_features = np.array(\n",
    "    [\n",
    "        \"acceleration\",\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "        \"horsepower\",\n",
    "        \"weight\",\n",
    "        \"year\",\n",
    "    ]\n",
    ")\n",
    "X = auto[numerical_features].copy()\n",
    "y = auto[\"mpg\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "\n",
    "For `p` in `[1, 2, 3, 4, 5]`, determine the subset of `numerical` of size `p` for which the linear model using precisely those features has the best predictive performance, as approximated by repeated 5-fold cross-validation.\n",
    "\n",
    "We'll start by doing things \"by hand\" and then refactor to incorporate some useful scikit-learn idioms: **transformers**, **pipelines**, and **grid search**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1\n",
    "\n",
    "Complete the implementation of the function `repeated_kfold_error` (fill in the `...`) whose goal is estimating the predictive error of a model using repeated $k$-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def repeated_kfold_error(model, X, y, *, n_splits=5, n_repeats=20, random_state=None):\n",
    "    n_fits = n_splits * n_repeats\n",
    "    errors = np.zeros(n_fits)\n",
    "    repeated_kfold = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    for i, (train, test) in enumerate(repeated_kfold.split(X)):\n",
    "        model.fit(..., ...)  # Your work here!\n",
    "        errors[i] = mean_squared_error(..., ...)  # Your work here!\n",
    "    return errors.mean()\n",
    "\n",
    "\n",
    "# check\n",
    "assert np.isclose(\n",
    "    repeated_kfold_error(LinearRegression(), X, y, random_state=42).mean(),\n",
    "    12.167089387362708,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides the convenience method `sklearn.model_selection.cross_val_score` for iterating over train/test splits arising from cross-validation, fitting models, and collecting prediction metrics.\n",
    "\n",
    "Scikit-learn conforms to standard English usage by considering higher scores to be better. For measures of error, on the other hand, lower is better. Thus, the negative of a score is an error measure, and vice versa. In particular, the scores returned by calls to `cross_val_score` with the `scoring` keyword argument set to `neg_mean_squared_error` are the negatives of the test set MSEs.\n",
    "\n",
    "##### Task 2\n",
    "\n",
    "Fill in the `...` on the last three lines of the cell below to verify that the errors returned by `repeated_kfold_error` are the negatives of the scores returned by `repeated_kfold_score` when these functions are passed the same `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def repeated_kfold_score(model, X, y, *, n_splits=5, n_repeats=10, random_state=None):\n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    "    )\n",
    "    scores = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "    return scores\n",
    "\n",
    "\n",
    "errors = repeated_kfold_error(LinearRegression(), X, y, random_state=...)\n",
    "scores = repeated_kfold_score(LinearRegression(), X, y, random_state=...)\n",
    "assert ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3\n",
    "\n",
    "Complete the implementation of the function `find_best_features` (fill in the `...`) whose goal is to find the set of features among those in `feature_lists` minimizing predictive error, as estimated by repeated $k$-fold cross-validation.\n",
    "\n",
    "The argument `feature_lists` is a list of lists of features of `X`. For example, `features_lists` might be the list of all pairs of features:\n",
    "\n",
    "```python\n",
    "feature_lists = [\n",
    "    [f, g]\n",
    "    for f in numerical_features\n",
    "    for g in numerical_features\n",
    "    if f < g\n",
    "]\n",
    "feature_lits\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```text\n",
    "[['acceleration', 'cylinders'],\n",
    " ['acceleration', 'displacement'],\n",
    " ['acceleration', 'horsepower'],\n",
    " ['acceleration', 'weight'],\n",
    " ['acceleration', 'year'],\n",
    " ['cylinders', 'displacement'],\n",
    " ['cylinders', 'horsepower'],\n",
    " ['cylinders', 'weight'],\n",
    " ['cylinders', 'year'],\n",
    " ['displacement', 'horsepower'],\n",
    " ['displacement', 'weight'],\n",
    " ['displacement', 'year'],\n",
    " ['horsepower', 'weight'],\n",
    " ['horsepower', 'year'],\n",
    " ['weight', 'year']]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_features(\n",
    "    model, X, y, feature_lists, n_splits=5, n_repeats=10, random_state=None\n",
    "):\n",
    "    best_features = []\n",
    "    best_score = -np.inf\n",
    "    for features in feature_lists:\n",
    "        score = repeated_kfold_score(\n",
    "            model,\n",
    "            ...,  # Your work here!\n",
    "            y,\n",
    "            n_splits=n_splits,\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_features = features\n",
    "    return best_features\n",
    "\n",
    "\n",
    "# check\n",
    "feature_lists = [\n",
    "    [f, g] for f in numerical_features for g in numerical_features if f < g\n",
    "]\n",
    "best_features, best_score = find_best_features(\n",
    "    LinearRegression(), X, y, feature_lists, random_state=42\n",
    ")\n",
    "assert best_features == [\"weight\", \"year\"]\n",
    "assert np.isclose(best_score, -11.87058663029629)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4\n",
    "\n",
    "Write a function `enumerate_sublists(n)` a positive integer `n` as input and produces, as output, a list `S` of length `n + 1` such that `S[i]` is a list consisting of all sublists of `list(range(n))` of size `i`. In particular, `S[0]` should be `[[]]` and `S[n]` should be `[list(range(n))]`. Arrange for `S[i]` to be ordered lexicographically.\n",
    "\n",
    "Flesh out the implementation below. If you don't like my approach (maybe you prefer recursion?), scap it and do your own thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_sublists(n):\n",
    "    S = [[[]], [[i] for i in range(n)], *[[] for _ in range(2, n + 1)]]\n",
    "    for i in range(2, n + 1):\n",
    "        for s in S[i - 1]:\n",
    "            S[i].extend(...)  # Your stuff here!\n",
    "    return S\n",
    "\n",
    "\n",
    "# check\n",
    "assert enumerate_sublists(3) == [\n",
    "    [[]],\n",
    "    [[0], [1], [2]],\n",
    "    [[0, 1], [0, 2], [1, 2]],\n",
    "    [[0, 1, 2]],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 5\n",
    "\n",
    "Embed `find_best_features` in a for-loop to find the optimal sets of numerical features of sizes 1 through 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(numerical_features)\n",
    "sublists = enumerate_sublists(p)\n",
    "for S in sublists[1:]:\n",
    "    feature_lists = [numerical_features[s] for s in S]\n",
    "    best_features, best_score = find_best_features(...)  # Your work here!\n",
    "    print(best_features, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfomers and pipelines\n",
    "\n",
    "**Transformers** are scikit-learn classes for transforming data, often part of a preprocessing step. Here's a simple transformer that extracts a given collection of columns from a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weight",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0afd2b7c-850d-4db8-b871-e5e45b291d2d",
       "rows": [
        [
         "0",
         "3504",
         "70"
        ],
        [
         "1",
         "3693",
         "70"
        ],
        [
         "2",
         "3436",
         "70"
        ],
        [
         "3",
         "3433",
         "70"
        ],
        [
         "4",
         "3449",
         "70"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3504</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3693</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3436</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3433</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3449</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight  year\n",
       "0    3504    70\n",
       "1    3693    70\n",
       "2    3436    70\n",
       "3    3433    70\n",
       "4    3449    70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class FilterFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None):\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return self\n",
    "        else:\n",
    "            raise TypeError(\"X must be a pandas dataframe.\")\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.loc[:, self.features]\n",
    "        else:\n",
    "            raise TypeError(\"X must be a pandas dataframe.\")\n",
    "\n",
    "\n",
    "# Demonstration\n",
    "\n",
    "F = FilterFeatures(features=[\"weight\", \"year\"])\n",
    "XX = F.fit_transform(X)\n",
    "display(XX.head())\n",
    "assert all(XX.columns == [\"weight\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers and estimators (models) can be composed into **pipelines**. Pipelines can be fit and used for prediction just like any other scikit-learn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 11.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(FilterFeatures(features=[\"weight\", \"year\"]), LinearRegression())\n",
    "model.fit(X, y)\n",
    "mse = mean_squared_error(y, model.predict(X))\n",
    "print(f\"mse = {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "\n",
    "Grid search fits a collection of models parametrized by a **parameter grid** to the same dataset in order to compare their performance. The `sklearn.model_selection.GridSearchCV` class does this comparison using cross-validation. Our `FilterFeatures`-`LinearRegression` pipeline is parametrized by the `features` parameter of the `FilterFeatures` step. Below, I use `GridSearchCV` to identify an optimal feature set from a collection, just like we accomplished above manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filterfeatures__features': ['weight', 'year']} -11.87058663029629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = make_pipeline(FilterFeatures(), LinearRegression())\n",
    "\n",
    "feature_lists = [\n",
    "    [f, g] for f in numerical_features for g in numerical_features if f < g\n",
    "]\n",
    "param_grid = {\"filterfeatures__features\": feature_lists}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=RepeatedKFold(random_state=42),\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "\n",
    "print(search.best_params_, search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6\n",
    "\n",
    "Refactor the function `find_best_features` from Task 3 to use `GridSearchCV` instead of hand-crafted the for loop. Call the new function `search_best_features`. Show that `find_best_features` and `search_best_features` give the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_best_features(\n",
    "    model, X, y, feature_lists, n_splits=5, n_repeats=10, random_state=None\n",
    "):\n",
    "    pipeline = make_pipeline(FilterFeatures(), model)\n",
    "    param_grid = ...  # Your work here!\n",
    "    scoring = ...  # Your work here!\n",
    "    cv = RepeatedKFold(\n",
    "        n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    "    )\n",
    "    search = GridSearchCV(pipeline, param_grid=param_grid, scoring=scoring, cv=cv)\n",
    "    search.fit(X, y)\n",
    "    best_features = ...  # Your work here!\n",
    "    best_score = ...  # Your work here!\n",
    "    return best_features, best_score\n",
    "\n",
    "\n",
    "# check\n",
    "feature_lists = [\n",
    "    [f, g] for f in numerical_features for g in numerical_features if f < g\n",
    "]\n",
    "a, b = find_best_features(LinearRegression(), X, y, feature_lists, random_state=42)\n",
    "aa, bb = search_best_features(LinearRegression(), X, y, feature_lists, random_state=42)\n",
    "assert a == aa\n",
    "assert np.isclose(b, bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 7\n",
    "\n",
    "Redo Task 5 using `search_best_features` from Task 6 in place of `find_best_features`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
