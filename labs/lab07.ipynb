{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 335 - Winter 2025 - Lab 6\n",
    "\n",
    "## Logistic regression: complete separation\n",
    "\n",
    "2025.03.11, 14:00-15:50, MS 521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import bambi as bmb\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function to load in classes 0 and 1 of the three class iris classification dataset that ships with Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris_01():\n",
    "    X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "    indices = np.logical_or(y == 0, y == 1)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:** Fit a Scikit-Learn logistic regression model (`sklearn.linear_model.LogisticRegression`) to the two-class iris data with `penalty` set to `None`. Verify that the training accuracy score (`sklearn.metrics.accuracy_score`) is `1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris_01()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:** Try using statsmodels to fit a logistic regression model (`statsmodels.api.Logit`) to the data. Expect warnings about \"perfect separation\" or \"possibly complete quasi-separation\". Note the sizes of the standard errors in the fit object returned by `Logit.fit`.\n",
    "\n",
    "Logistic regression models are fit by trying to find the coefficient vectors $c$ that minimize **log-loss**:\n",
    "$$\n",
    "\\min_c L(c)\n",
    "\\tag{$*$}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "L(c) = - \\frac1n\\sum_{i<n}\\left(y_i\\log\\sigma(c\\cdot x_i) +  (1 - y_i)\\log(1 - \\sigma(c\\cdot x_i))\\right)\n",
    "$$\n",
    "\n",
    "When the classes are linearly separable &mdash; there's a hyperplane in features space with all of class 0 on one side and all of class 1 on the other &mdash; then ($*$) has no solution.\n",
    "\n",
    "In what follows, we'll figure out why this is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset has a 4-dimensional feature space. Let's take a step back and consider the 1-dimensional case.\n",
    "\n",
    "Here's a construction of a classification dataset with a single feature $x$ and perfect separation according to whether $x>0$ or $x<0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAEpCAYAAAAQ+2zYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMOFJREFUeJzt3Qd4FNXaB/D/bnoCCSWQUEJTREEg9BsREY0EQRQrINcAUkTRiyAtKiAgRgG5KEQRLkW/i4IoyFUwXGlX0UhJLICA0gMYegqpJDvf8x7YNZtskt2QTTaT/+95BmZmp5yZ2cw758w5Zw2apmkgIiLSEWNFJ4CIiKisMbgREZHuMLgREZHuMLgREZHuMLgREZHuMLgREZHuMLgREZHuMLgREZHuMLgREZHuMLhRlTJnzhw0a9YMbm5uCA0NrejkVGlDhgxBkyZNKjoZpFMMblShVqxYAYPBYBm8vb1xyy234Pnnn8fZs2fLdF///e9/MXHiRHTt2hXLly/HG2+8gbK2ceNGvPbaa2W+3crqzJkz6nz8/PPPFZ0UqmLcKzoBRGLGjBlo2rQpsrKysGPHDrz//vsqUOzbtw++vr5lso+tW7fCaDRi6dKl8PT0hDNImmNiYhjg8gW36dOnqxxawZzykiVLYDKZKixtpG8MbuQS7r//fnTs2FGNDx8+HLVr18a8efOwfv16DBw48Ia2nZGRoQLkuXPn4OPj47TAVhXIw4ecP3lIuFEeHh5lkiYiW1gsSS7pnnvuUf8fO3bMMu/f//43OnTooAJUrVq1MGDAACQmJlqtd/fdd+P2229HfHw87rrrLhXUXn75ZVXkKUWR6enpliJQKRJ1ZNti586d6N27N2rWrAk/Pz+0adMG77zzjuUdkuTaRP6i1uLs2bMHERERCAwMVPuW3OvTTz9ttYzkbubPn49WrVqpYtugoCA888wzuHz5stVykjt64IEHVPGr5JJk2ZYtW2Lt2rVWy126dAnjx49H69atUa1aNfj7+6uHi19++cVque3bt6v0r1q1Cq+++ioaNGigzmdqaqpd25D1O3XqpMaHDh1a6Lzbeucm1+ell15CSEgIvLy80KJFC8ydOxcFf7xEtiNF11988YW63rKsnJ/Y2NhizzdVHcy5kUs6cuSI+l9ycGLWrFmYMmUKnnjiCZWzO3/+PBYsWKAC2E8//YQaNWpY1r148aK60UqA+vvf/66CgeQKFy9ejF27duFf//qXWu6OO+5waNvffPONCh716tXDmDFjEBwcjAMHDuCrr75S0xJwpBhOlvu///u/Eo9RcpI9e/ZEnTp1MHnyZLWf48ePFwpGsl0JCBIg/vGPf6iAv3DhQpW277//3ioH9Mcff6B///4YNWoUBg8erAL6448/rm769913n1rm6NGjKijIfAmm8m7zgw8+QPfu3fHbb7+hfv36VvufOXOmyq1JMMvOzlbjslxJ27jttttUcfPUqVMxcuRIdOvWzeq8FyQB7MEHH8S2bdswbNgwFaA3bdqECRMm4PTp0/jnP/9ptbwUX8u5eu6551C9enW8++67ePTRR3Hy5EnL94aqMPk9N6KKsnz5cnkk1zZv3qydP39eS0xM1FatWqXVrl1b8/Hx0U6dOqUdP35cc3Nz02bNmmW17t69ezV3d3er+d27d1fbW7RoUaF9DR48WPPz87OaZ++2c3NztaZNm2qNGzfWLl++bLWsyWSyjI8ePVrt3x7r1q1Ty+7evbvIZb777ju1zMqVK63mx8bGFpovaZN5n3/+uWVeSkqKVq9ePa1du3aWeVlZWVpeXp7V9o4dO6Z5eXlpM2bMsMzbtm2b2l6zZs20jIwMq+Xt3YYcm2xDrrOt6yFpNvviiy/Usq+//rrVco899phmMBi0w4cPW+bJcp6enlbzfvnlFzV/wYIFNs4kVTUsliSXEB4ernIwUhwlOS4p6lq3bp0qCpOncymak5zVhQsXLIPknJo3b66e9POTIirJ5djD3m1LLklyTC+++KJVLlGUVPRYFPN2JOd39epVm8usWbMGAQEBKteVP31ShCrnqOCxS47p4YcftkxLcWFkZKRKf1JSkuX8mN+Z5eXlqZyubEuKABMSEgqlQXKAUmSan6PbsLcyjjTRkNxpflJMKfHs66+/LvSduemmmyzTUkQsxys5UyIWS5JLkHdV0gTA3d1dFSPKTdJ885SiNrm5SbCxp2KCBER7K43Yu21zMam83ykrUoQnxWhSm1CK3OR9Yb9+/fDkk0+q4GFOX0pKCurWrVtk0WZ+N998c6FgK+dVSJGnBG0J5vKe8L333lMBW4KTma3iPCl2LMjRbdjjxIkTKjhLEWN+Urxp/jy/Ro0aFdqGvAst+C6SqiYGN3IJnTt3ttSWtHUjlRu2PLnLk31BkmPIr2AuoziObrssyX4/++wz/Pjjj/jyyy/V+yWpTPL222+rebJvSZ8EtpUrV9rchuR2HSXt++Qdo+xL3qdJBRp5kJBcqa2q+bbOp6PbcAZb10sUrHxCVRODG7k8KXqSG5bkIMy5kPLetrn4S9rdSXFYUUpTRPm3v/1NDVKx5eOPP8agQYNUDUWp3CL73bx5s2p4bk/QPnz4sDqe/On4/fff1f/mmokSUHv06KHa++WXnJysam3aw95tOHI+GjdurI41LS3NKvd28OBBy+dE9uI7N3J5jzzyiHpKl+K7gk/lMi3ve5y97fbt26sAKFXy5QZecDkzaR4gCi5jixSfFdynuaGz1EoU8i5Qivwkd1RQbm5uof1IbU15V2km1fY/+ugjtV0pkhRyvAX3K+/2pEaivezdhiPnQ5pYyLFKTdD8pMhWgqTUgCWyF3Nu5PIk9/L6668jKipKvTeS91LyZC/veuRGLtXMpZq6M7ctRW7Sa0rfvn1VoJAKK9IkQHIV+/fvV0WKQip6CKkUIe3XJAhIBRlbPvzwQ/XOSiqASDokxyK9dkilCLnRm9/LSVOA6Oho1YWVNB2Q94DyLk6Cibz3euyxxyzblNynVKPfvXu3ene5bNkyVU1fmgSYSXMGqaIvxyDV8vfu3auKPaXPTXvZuw05Lqk4s2jRInVeJdh16dLF5ns8ObeSG3zllVfUtWjbtq1qsycN+aW4M3/lEaISVXR1TarazE0BiqsObyZV3O+8805VnV+GW2+9VVW9P3TokFVTgFatWtlc31ZTAEe2LXbs2KHdd999WvXq1dVybdq0sap6Lk0GXnjhBa1OnTqq+npxf2IJCQnawIEDtUaNGqkq9HXr1tUeeOABbc+ePYWWXbx4sdahQwfVPEL23bp1a23ixInamTNnLMtItfo+ffpomzZtUumSbcpxrFmzplA1/pdeekk1EZDtde3aVYuLi1PnToaCTQEKru/INsT69eu1li1bqqYV+ZsFFGwKINLS0rSxY8dq9evX1zw8PLTmzZtrc+bMsWpuIWQ7cn0Kku3JdokM8k/JIZCIXJ28U5PanNK0gKiq4zs3IiLSHQY3IiLSHQY3IiLSHb5zIyIi3WHOjYiIdIfBjYiIdKdSNOKWvuqk5wVpBFraHtiJiKhyk7do0tmBdLBd0q/BV4rgJoFNfgqFiIgoMTERDRs2rPzBzdyJqhyQdE1ERERVT2pqqsroFPxZpEob3MxFkRLYGNyIiKo2gx2vp1ihhIiIdIfBjYiIdIfBjYiIdIfBjYiIdIfBjYiIdIfBjYiIdIfBjYiIdIfBjYiIdKdSNOImosorLy8PCQkJarx9+/Zwc3Or6CRRFcDgRkROJcGsU6dOFZ0MqmJYLElERLrDnBsROVVOTg7eeecdNT5mzBh4enpWdJKoCjBo8gM5laAn6ICAAKSkpLDjZKJKJj09HdWqVVPjV65cgZ+fX0UniSopR2IBiyWJiEh3GNyIiEh3GNyIiEh3GNyIiEh3GNyIiEh3GNyIiEh32M6NiJzK29sb27Zts4wTlQcGNyJyevdbd999d6H5qont1T3QsrcDWg4MHrcB3r1hMFwLgFrOL9CyNwNaJgzuNwPefWEwlr6NnJZ3Gsj8DzTTBRiMdQGfh2BwC76elkwgcyO03AOAwQsGr3sAj/YwGAy2050TBy37O+k5EwaP1oB3BAyG8mucruWdATLXq2OBQc6JG6ClAoYAGHwegMG9me31NA1a5idA5jp1zuHeEqg+Hka32tc+v/ortKxv8p3zB2AwVrvBtF4Estar828w1ri2TfemcLlG3N9++y3mzJmD+Ph4/Pnnn1i3bh369etX7Drbt2/HuHHjsH//foSEhODVV1/FkCFD7N4nG3ET6YuWdwFa8ijg6q/XbsyQIJILGKoDAdFAxkoVQKw/84Uh4C0YvCMc25dmgpb2FpCx4vq25G2M6dqHfs8AHu2AlHGAduX6877cEvOuBbea78FgrJUv3X9CuzwSyD2UL28gaasJQ80YGDw7luVpKuJY5gAZy64fC/46FnVcMi8P8O4HQ8DrVgHXdPUocOlRQEsvvGFfOaZ9QM4PBc65z/Vz3qt06U1fBi1t7rU0qe1eP7fej8AQMBMGg4frNOKW3gbatm2LmJgYu5Y/duwY+vTpgx49euDnn3/Giy++iOHDh2PTpk2O7pqIKqGrV6+q+4UMMq5pedAuDwWu7r++hNz4cq+NSoBJfgHI2Wnjs0xoyWOg5exxLAHpMUDG8us3VtP17cn/JiD9fUCCrOWGn3t9n5LwX6BdGqECitq9lgPtUiSQezjfsua0pUC7NAxa7onSnyi7juV9IGNpvmMxBzZcH7+e9qz10FJn/vWJKQe42M92YBMZi68/TBQ851nQkl+ElrPb4aRqmeugpb15fVua9bnNWgctdRZctvstybKXlHObNGkSNmzYgH379lnmDRgwAMnJyYiNjbVrP8y5Eemn+y1ftx+hJT9byq0ZAc+uMNaSG3zJNNMVaOe6Asgs5f4kU7YUBq9u0KQYMGVCMUu6Ab4DYPSfBmfQTBnQzoepIG8fIwx1tquiV9OV94Ar80u5ZzfA828w1lruWA7z/D2A6UwJ6fsWBre6lbP7rbi4OISHh1vNi4iIUPOLkp2drQ4i/0BE+qBlyUNtaX/TzQTk7FA3eruoYrbSBzZJ57X0mtNd3C0zD8jcAKeRY7E7sAkNyN6ixpD5BUovD8j5Xj0o2C33YAmBrUD6nMDpwS0pKQlBQUFW82RaAlZmpu0LFR0draKzeZD3dESkE1pGgeI0hzcg5VoO7OtGaH9tQ72TKyHdDgUfR5Pi6LEYAfNDgJZdBvvPKuO0Gsrg+lSydm5RUVEq22keEhMTKzpJRFRWVE2+G7j1GAKuDXbv68YY3G+6vq2bS8hxGspkf0VyeNt5gDntbjeYQTD4A1LT0V5uje24xibArVnlDW7BwcE4e/as1TyZlvJSHx8fm+t4eXmpz/MPRKQPBp8nbiDnZgR8B8JgsLNY07014H5LMbe6wlX9C/F57NqSPgP+qhBhkwaD7yA4jXsrwP02O2/bBsAYCHjddW2y+vgb2LGc8wEwGOxvOWZwqwNIc4oiHwaMgDTHMKevMga3sLAwbNliXa76zTffqPlEVPUY3ENgqD7RPFXgU+P1p/7r4wU/c28Og99I+/dlMKiq7NJ2rfCNVqZ9ATdbwe/atKH6y5a2cAaPFoDf6CLSbQA8uwE+D8NZrh1LdBHHkp985gZDwBxLQDJ6hgJePYtZx6OYc34zDH6jHE+v/6uAsWYR5914PX2lfffqhOAmtZ2kSr8M5qr+Mn7y5ElLkWJkZKRl+VGjRuHo0aOYOHEiDh48iPfeew+ffvopxo4dW5bHQUSViMFvGAw13gXcb803swbgNwqGwC9hqLkE8GiT77NqgO9QGGp94nCjYoNHKxhqfw543ZfvlucGeN8PQ+A6GGp/CviNsC7qdG8JQ40YGPz+upcJY/Ux6qYMt5vyzawNQ7UxMNR83+F2W44yeLS8fiw9C9y+jfmCbNdr58lLaonmW6LmQkA9GBToJcY9FJBaizX/BXi0LXDOh5TqnKvV3erDUHutanMHeOZL350w1F4Fg1eYazUFkAbZ0matoMGDB2PFihWqcfbx48fVcvnXkWD222+/oWHDhpgyZQobcRNVEbm5uZZ2rVJT2t3dvVCDbiAHMNYpFBw006VrFRmMgWXSA4iq8WdKVjmKgr2daNpVwHReXozAcL3HjiK3I7dN6R1E2m4Z6zo1B1LysdSQSAJITyBGfxiMxd8jVS8l0lZPS1MPF0ajr41znnn9epRNryuqBxg701dWseCG2rmVFwY3IiJKdaV2bkREROWNHScTkVNJl1srV65U44MGDYKHh3PfSxEJFksSUbl2v+XnV/qe/alqS2WxJBERVWUMbkREpDsMbkREpDsMbkREpDsMbkREpDsMbkREpDts50ZETiW/8iH9yZrHicoDgxsROZX0Jfn4449XdDKoimGxJBER6Q5zbkTk9F8FWLdunRp/+OGHC/0qAJEz8FtGRE6VnZ2NJ554wtL9FoMblQcWSxIRke4wuBERke4wuBERke4wuBERke4wuBERke4wuBERke6wTi4ROZWnpyeWL19uGScqDwxuRORUHh4eGDJkSEUng6oYFksSEZHuMOdGRE7vfmvTpk1qPCIigj2UkOvm3GJiYtCkSRN4e3ujS5cu2LVrV7HLz58/Hy1atICPjw9CQkIwduxYZGVllTbNRFTJut964IEH1CDjRC4Z3FavXo1x48Zh2rRpSEhIQNu2bdXT2Llz52wu//HHH2Py5Mlq+QMHDmDp0qVqGy+//HJZpJ+IiOjGg9u8efMwYsQIDB06FC1btsSiRYvg6+uLZcuW2Vz+hx9+QNeuXfHkk0+q3F7Pnj0xcODAEnN7RERE5RLccnJyEB8fj/Dw8L82YDSq6bi4OJvr3HHHHWodczA7evQoNm7ciN69exe5Hym6SE1NtRqIiIjs5dCb3QsXLiAvLw9BQUFW82X64MGDNteRHJusd+edd0LTNPVyedSoUcUWS0ZHR2P69OmOJI2IiKj8mgJs374db7zxBt577z31jm7t2rXYsGEDZs6cWeQ6UVFRSElJsQyJiYnOTiYREVXVnFtgYCDc3Nxw9uxZq/kyHRwcbHOdKVOm4KmnnsLw4cPVdOvWrZGeno6RI0filVdeUcWaBXl5eamBiIjI6Tk36TqnQ4cO2LJli2WeyWRS02FhYTbXycjIKBTAJEAKKaYkIn2T+8bChQvVwO63qLw43JpSmgEMHjwYHTt2ROfOnVUbNsmJSe1JERkZiQYNGqj3ZqJv376qhmW7du1Um7jDhw+r3JzMNwc5ItJ391ujR4+u6GRQFeNwcOvfvz/Onz+PqVOnIikpCaGhoYiNjbVUMjl58qRVTu3VV1+FwWBQ/58+fRp16tRRgW3WrFlleyRERETXGbRKUDYoTQECAgJU5RJ/f/+KTg4ROUBqWH/33XdqvFu3biyxoXKJBezkjYicSrra69Gjhxq/cuUK/Pz8KjpJVAXwVwGIiEh3GNyIiEh3GNyIiEh3GNyIiEh3GNyIiEh3GNyIiEh32BSAiJzeQ8ns2bMt40TlgY24iYioUnAkFrBYkoiIdIfFkkTk9O635LccRfv27dn9FpULBjcicnr3W/ILIoLdb1F5YbEkERHpDoMbERHpDoMbERHpDoMbERHpDoMbERHpDoMbERHpDpsCEJFTSZdb06ZNs4wTlQd2v0VERJUCu98iIqIqjcWSRORUJpMJBw4cUOO33XYbjEY+U5PzMbgRkVNlZmbi9ttvV+PsfovKCx+hiIhId0oV3GJiYtCkSRN4e3ujS5cu2LVrV7HLJycnY/To0ahXrx68vLxwyy23YOPGjaVNMxERUdkWS65evRrjxo3DokWLVGCbP38+IiIicOjQIdStW7fQ8jk5ObjvvvvUZ5999hkaNGiAEydOoEaNGo7umoiIyDlNASSgderUCQsXLrS8LA4JCcELL7yAyZMnF1peguCcOXNw8ODBUrdxYVMAosorPT0d1apVU+N850Yu2RRAcmHx8fEIDw//awNGo5qOi4uzuc5//vMfhIWFqWLJoKAg9WL5jTfeUD9gWJTs7Gx1EPkHIiIiezkU3C5cuKCCkgSp/GQ6KSnJ5jpHjx5VxZGynrxnmzJlCt5++228/vrrRe4nOjpaRWfzIDlDIiIil2kKIMWW8r5t8eLF6uflO3TogNOnT6uiSnOXPAVFRUWp93pmknNjgCOqnOR1xPjx4y3jRC4X3AIDA1WAOnv2rNV8mQ4ODra5jtSQlC+0rGcmDTklpyfFnJ6enoXWkRqVMhBR5Sd/4/IwS+SyxZLyJZWc15YtW6xyZjIt79Vs6dq1Kw4fPqyWM/v9999V0LMV2IiIiMq9nZsUFy5ZsgQffvih6lLn2WefVbWhhg4dqj6PjIxUxYpm8vmlS5cwZswYFdQ2bNigKpRIBRMi0j95sD1+/Lga8j/kErnUO7f+/fvj/PnzmDp1qipaDA0NRWxsrKWSycmTJ636jpN3ZZs2bcLYsWPRpk0b1c5NAt2kSZPK9kiIyGW732ratKkaZ1MAKi/8yRsiciq2c6Oywp+8ISKiKo3BjYiIdIfBjYiIdIfBjYiIdIfBjYiIdIe/xE1ETuXu7o7nnnvOMk5UHvhNIyKnkq705AeOicoTiyWJiEh3mHMjIqeSfiLk57LMna8bDIaKThJVAQxuRORUGRkZ6mevBHsoofLCYkkiItIdBjciItIdBjciItIdBjciItIdBjciItIdBjciItIdNgUgIqeSLrcGDx5sGScqD/ymEZHTu99asWJFRSeDqhgWSxIRke4w50ZETu9+S3opEb6+vux+i8oFc25E5FQS2KpVq6YGc5AjcjYGNyIi0h0GNyIi0h0GNyIi0p1SBTf5Vd0mTZrA29sbXbp0wa5du+xab9WqVeplcr9+/UqzWyIiIucEt9WrV2PcuHGYNm0aEhIS0LZtW0RERODcuXPFrnf8+HGMHz8e3bp1c3SXREREzg1u8+bNw4gRIzB06FC0bNkSixYtUtV7ly1bVuQ6eXl5GDRoEKZPn45mzZo5uksiIiLntXPLyclBfHw8oqKiLPOMRiPCw8MRFxdX5HozZsxQv8Q7bNgwfPfddyXuJzs7Ww1mqampjiSTiFyIm5sbHnvsMcs4kcsFtwsXLqhcWFBQkNV8mT548KDNdXbs2IGlS5fi559/tns/0dHRKpdHRJWfvJtfs2ZNRSeDqhin1pZMS0vDU089hSVLliAwMNDu9SRnmJKSYhkSExOdmUwiIqrKOTcJUFKscPbsWav5Mh0cHFxo+SNHjqiKJH379rXMM5lM13bs7o5Dhw7hpptustnRqgxEREROz7l5enqiQ4cO2LJli1WwkumwsLBCy996663Yu3evKpI0Dw8++CB69OihxkNCQkqVaCKqPNLT01UTIBlknMglO06WZgDy20wdO3ZE586dMX/+fPWFldqTIjIyEg0aNFDvzaSs/fbbb7dav0aNGur/gvOJiIgqLLj1798f58+fx9SpU5GUlITQ0FDExsZaKpmcPHlS1aAkIiKqKAZNfo/CxUlTgICAAFW5xN/fv6KTQ0QOkJId+UUAceXKFfj5+VV0kqiSciQWMItFRES6w+BGRES6w+BGRES643CFEiIiR0jb2N69e1vGicoDgxsROZU0CdqwYUNFJ4OqGBZLEhGR7jC4ERGR7jC4EZHT27lJ2zYZ2P0WlRe+cyMip8vIyKjoJFAVw5wbERHpDoMbERHpDoMbERHpDoMbERHpDoMbERHpDmtLEpFTye87du/e3TJOVB4Y3IjIqXx8fLB9+/aKTgZVMXyMIiIi3WFwIyIi3WFwIyKnki636tSpowZ2v0Xlhe/ciMjpLly4UNFJoCqGOTciItIdBjciItIdBjciItIdBjciItKdUgW3mJgYNGnSBN7e3ujSpQt27dpV5LJLlixBt27dULNmTTWEh4cXuzwREVG5B7fVq1dj3LhxmDZtGhISEtC2bVtERETg3LlzNpeXngkGDhyIbdu2IS4uDiEhIejZsydOnz59w4knItcnXW517NhRDex+i8qLQdM0zZEVJKfWqVMnLFy4UE2bTCYVsF544QVMnjy5xPXz8vJUDk7Wj4yMtGufqampCAgIQEpKCvz9/R1JLhER6YQjscChx6icnBzEx8erokXLBoxGNS25Mnt/bv7q1auoVatWkctkZ2erg8g/EBER2cvoaENMyXkFBQVZzZfppKQku7YxadIk1K9f3ypAFhQdHa2is3mQnCEREZG9yrUA/M0338SqVauwbt06VRmlKFFRUSrbaR4SExPLM5lEVIaktEYqoMkg40Qu1/1WYGAg3NzccPbsWav5Mh0cHFzsunPnzlXBbfPmzWjTpk2xy3p5eamBiCo/ea1/4sQJyziRy+XcPD090aFDB2zZssUyTyqUyHRYWFiR682ePRszZ85EbGysqjFFRETkUh0nSzOAwYMHqyDVuXNnzJ8/X/X0PXToUPW51IBs0KCBem8m3nrrLUydOhUff/yxKpYwv5urVq2aGoiIiCo8uPXv3x/nz59XAUsCVWhoqMqRmSuZnDx50qoty/vvv69qWT722GNW25F2cq+99lpZHAMREdGNtXOrCGznRlR5ScmOuZTmypUr8PPzq+gkUSXltHZuRERElQF/rJSInMpgMKBly5aWcaLywOBGRE7l6+uL/fv3V3QyqIphsSQREekOgxsREekOgxsROZV0udWqVSs1sPstKi9850ZETiWtjX777TfLOFF5YM6NiIh0h8GNiIh0h8GNiIh0h8GNiIh0h8GNiIh0h7UlicippMutxo0bW8aJygODGxE5vfut48ePV3QyqIphsSQREekOgxsREekOgxsROVVmZiY6deqkBhknKg9850ZETmUymbBnzx7LOFF5YM6NiIh0h8GNiIh0h8GNiIh0h8GNiIh0h8GNiIh0p0rUljy27yT+9+kPSE/OQP2bg3Hv37vBv1b1ik6Wy7l8Nhmb//0dzp04D//A6ugx8E40bF6vfPdbuzp6PFl4vzlZOfju8504tPswPDzd0bFXKEJ73F5kd04Hdx/Gp7PX48yRJHWtew2/B90fD4Obmxv07PThP7H14x1IvZCGuo0CEf7UXagZVMPp+83Jvooda3fi0K7DcHM3ouUdLXD+1EWc+SMJ7j5G1KpZC0Y3PktT+TFopfhp3JiYGMyZMwdJSUlo27YtFixYgM6dOxe5/Jo1azBlyhTVBU/z5s3x1ltvoXfv3nbvLzU1FQEBAUhJSYG/v7/d62VnZmP2kBh8uyZO/cHJjTAv1wR3TzeMfudp9Bl5n93b0rtP56zHslc+hsmkwc3NqP435Zlw//B78Y+Y4XD3cC/X/fZ6ugfGvD9S7ffXb3/D9EfnIvViGtw83AANyMvNw01tG+P1r6IQ2KC2ZXsZaZl4pc8b2LfjYKF9BdTxx9vbp6PxbQ2hN3I+3h29BBuXbFFBxGg0IC/PpP4fMmMABkx+2Gn73vf9Qbz2yByknE9V10fLM6nrKOTv7lr6TLjjoU6IWjkG3r5eTksL6VuqA7HA4Uep1atXY9y4cZg2bRoSEhJUcIuIiMC5c+dsLv/DDz9g4MCBGDZsGH766Sf069dPDfv27YOzvT38fez4/EfLH1fu1Tz1M/dXs3Mxf9Ri7Fi30+lpqAy+XroFSyb9W50jzaSp8yQBRsQu3YoPxn/klP3GLtta5H43Ld+ORS99iFO/n0FUr1m4cvmKmp93NU/dyMXx/YmYED4DV3OuWrY57eHZNgObkJvvmK6vIvVSGvTmgwkf4et/bVXjcg7Vd92kqXO79OWPsXHJZqfsV3LGkyNeVw8e5utjDmxqOtekBvHjV/GYPWShU9JBdMPBbd68eRgxYgSGDh2Kli1bYtGiRapj1GXLltlc/p133kGvXr0wYcIE3HbbbZg5cybat2+PhQud+yU/9cef2PbJ91Z/aPlJLu7DaatVsKvK8vLy8NFrnxb5uZyfL9/fhMvnUsp+v9OL3+9Xi/6LlbM+R15urs3rKDfNU4fOYMfaXWr60J4j+Hlr8Q9N6cnpKmDrSfL5FPwnZlOx32U513LOy9ra+RuQm3NVBdKSSND97rMfceLAqTJPB9ENBbecnBzEx8cjPDz8rw0YjWo6Li7O5joyP//yQnJ6RS0vsrOzVfYz/+Co79ftKraMX24Ex/clIumY7RxnVXE44RgunL5U7DISRH78ck/Z7ven4zifeLHE/crN0Pzkb4sUu3372bXvkrzzsceWld9CT378KsGSmy3KxTOX8fueo2W+722rvy/2+og8LQ97tO1q0Iwm7PicJSbkYsHtwoUL6ukvKCjIar5My/s3W2S+I8uL6OhoVa5qHkJCQuCozCuZMBhL/u2ozCtZqMrsOX45j2V9nrLs2J4Erqs5ucUuIzm6zLRMu7cp0lP01b+hHHdFfdez07PtWEpDMi6o4dp3SV/nn1yTS1ZfioqKUi8MzUNiYqLD22h0awNV/l8cd093BDUORFXWQGollnBflCKnRmVcCaNB8+ASf7hSAldgw1oobjGpsNC45bWHn5BbG9i172Ztr/1wpl6E3Fq/5GJBA9DwlrKv+dqwRX27AquZ/E2W9XeJ6IaDW2BgoKpKffbsWav5Mh0cHGxzHZnvyPLCy8tL1YTJPzjqzke6oFpNvyJvjEZ3I+598k74BfihKqvTsDY6925fZBGu3LikSnn78NZlul+p4djlgaL3K7m2OiG10X/CQ1I5skhSJNZ7xL1q/N5Bd6oHlpI8NLoX9KTdva0R1LhOkUFGznHn+9uhbkjZP8jJubTnfZuZj7837no8rMzTQXRDwc3T0xMdOnTAli1bLPOkl2+ZDguz/YWV+fmXF998802Ry5cVT29PTFzxPAxGY6EbqEzXaVAbT7/xpFPTUFk8/+7TqF6rmgr4Bc+Tu4cbJn74vHq3Wtaemz9U7dfNxn6N7m6Y9NELqilCu3taF7pxm6cjX3vCknOTB5WX/vVssfuUdl/tw9tAT+TayLmSa1Xwuy7ntnrNanj+3WFO2fd9kd3RMSLU7tzbmPefYVMAKhcO37GkGcCSJUvw4Ycf4sCBA3j22WeRnp6uak+KyMhIVaxoNmbMGMTGxuLtt9/GwYMH8dprr6mfv3j++efhbGF9O+Ltba+h7d2tLPO8fDzRZ0Q4FuyMRq3gmk5PQ2VQr2kQ3tv9Ju77+12WnI/crORp/53vZ6Ft91bO2++etxCef78G835fV/v18PRQbdkipz2BGnUDLOs2btkQUf/+B56a+rjVNmVb0bGvoF4z6/e8vv4+GP7W3zFh+egSi0Mro9bdblPXqnPvdpZAI+f03kF3IWb3m4XOR1mRdogz1k/E4On9UTPor+sjpSa2ctFdH+rklHQQlUkjbqnGb27EHRoainfffRddunRRn919991o0qQJVqxYYdWI+9VXX7U04p49e3a5NOK22salNGSmZaFGXX94+fDJsShZGdlIPpeC6jX9yrXI1p79So3Ai2cuqZum9LpRUpC6fC4Zfx49h5p1/RHUpK5Tcp+uKD0lHWmX01WjdR8/73Lbr1Q2k1qZbu5uqBVcA1ezr+Ly2RSYjHmo3+ja+74rV67Az69qvwqg0nMkFpQquJW3sghuRFQxpGSnbt26alw6e2Bwo/KIBVWib0kiqjgSzCTAEZWnqlFOQ0REVQqDGxER6Q6DGxE5VVZWFvr06aMGGScqD3znRkROr0W5ceNGyzhReWDOjYiIdIfBjYiIdIfBjYiIdIfBjYiIdIfBjYiIdIfBjYiIdIdNAYjI6d1vVYIubElnmHMjIiLdYXAjIiLdYXAjIiLdYXAjIiLdYXAjIiLdYXAjIiLdYXAjIiLdYXAjIiLdqRSNuM0NQFNTUys6KUREVEHMMcCeTgEqRXBLS0tT/4eEhFR0UoiIyAViQkBAQLHLGLRK0C+OyWTCmTNnUL16dRgMBruiuwTCxMRE+Pv7Q494jPpQFY6xqhwnj9H5JFxJYKtfvz6MRmPlz7nJQTRs2NDh9eTk6/VLZsZj1IeqcIxV5Th5jM5VUo7NjBVKiIhIdxjciIhId3QZ3Ly8vDBt2jT1v17xGPWhKhxjVTlOHqNrqRQVSoiIiFDVc25ERFS1MbgREZHuMLgREZHuMLgREZHuVPrgdvz4cQwbNgxNmzaFj48PbrrpJlWbJycnp9j1srKyMHr0aNSuXRvVqlXDo48+irNnz8KVzZo1C3fccQd8fX1Ro0YNu9YZMmSI6tUl/9CrVy/o6RilTtTUqVNRr1499R0IDw/HH3/8AVd16dIlDBo0SDWClWOU7++VK1eKXefuu+8udB1HjRoFVxITE4MmTZrA29sbXbp0wa5du4pdfs2aNbj11lvV8q1bt8bGjRvh6hw5xhUrVhS6ZrKeK/v222/Rt29f1QOIpPeLL74ocZ3t27ejffv2qgblzTffrI7bFVT64Hbw4EHVPdcHH3yA/fv345///CcWLVqEl19+udj1xo4diy+//FL9gf3vf/9T3Xs98sgjcGUSsB9//HE8++yzDq0nwezPP/+0DJ988gn0dIyzZ8/Gu+++q677zp074efnh4iICPUA44oksMl39ZtvvsFXX32lbigjR44scb0RI0ZYXUc5blexevVqjBs3Tj1YJiQkoG3btuoanDt3zubyP/zwAwYOHKgC+08//YR+/fqpYd++fXBVjh6jkAeY/NfsxIkTcGXp6enquCSI2+PYsWPo06cPevTogZ9//hkvvvgihg8fjk2bNqHCaTo0e/ZsrWnTpkV+npycrHl4eGhr1qyxzDtw4IA0idDi4uI0V7d8+XItICDArmUHDx6sPfTQQ1plY+8xmkwmLTg4WJszZ47V9fXy8tI++eQTzdX89ttv6nu2e/duy7yvv/5aMxgM2unTp4tcr3v37tqYMWM0V9W5c2dt9OjRlum8vDytfv36WnR0tM3ln3jiCa1Pnz5W87p06aI988wzml6O0ZG/U1cEQFu3bl2xy0ycOFFr1aqV1bz+/ftrERERWkWr9Dk3W1JSUlCrVq0iP4+Pj8fVq1dV8ZWZFI80atQIcXFx0BspNqhbty5atGihckQXL16EXsiTY1JSktW1lL7npMjIFa+lpEmKIjt27GiZJ2mX/lMl11mclStXIjAwELfffjuioqKQkZEBV8lty99U/msgxyPTRV0DmZ9/eSG5IFe8ZqU9RiHFzY0bN1adDT/00EMqx64ncS58HStFx8mOOHz4MBYsWIC5c+cWuYzcDD09PQu90wkKClKf6YkUSUpxq7yTPHLkiCquvf/++9WXz83NDZWd+XrJtasM11LSJA8a+bm7u6uHseLS++STT6qbpLwL+fXXXzFp0iQcOnQIa9euRUW7cOEC8vLybF4DeW1gixxrZblmpT1GeZhctmwZ2rRpox645Z4k75MlwJWmI3hXlFTEdZRfD8jMzFTvwCuKy+bcJk+eXOhlbMGh4Jfq9OnT6mYu72zk/URlUJrjdMSAAQPw4IMPqhf28k5D3vHs3r1b5eb0coyuwNnHKO/k5IlYrqO8s/voo4+wbt069cBCriksLAyRkZEIDQ1F9+7d1YNInTp1VP0AqsI5t5deeknV9CtOs2bNLONSIUReasqT0eLFi4tdLzg4WBUzJCcnW+XepLakfObKx3mjZFtStCU53HvvvReV/RjN10uundSWNJNpuamUF3uPUdJbsAJCbm6uqkHpyHdPil2FXEepIVyR5PskpQAFaxsX9/ck8x1ZvqKV5hgL8vDwQLt27dQ104vgIq6jVKSpyFybSwc3ecKRwR6SY5PA1qFDByxfvrzEH7GT5eSLtmXLFtUEQEgRz8mTJ9XTlqseZ1k4deqUeueWPxBU5mOU4lb5A5NraQ5mUiQi768crVVaHsco3y95qJL3N/I9FFu3blU1fs0Byx5SM02U53UsihTxy7HINZDSASHHI9PPP/98kedBPpfadWZSe7S8//6ceYwFSbHm3r170bt3b+hFWFhYoSYcLnMdtUru1KlT2s0336zde++9avzPP/+0DPmXadGihbZz507LvFGjRmmNGjXStm7dqu3Zs0cLCwtTgys7ceKE9tNPP2nTp0/XqlWrpsZlSEtLsywjx7l27Vo1LvPHjx+vaoAeO3ZM27x5s9a+fXutefPmWlZWlqaHYxRvvvmmVqNGDW39+vXar7/+qmqHSm3ZzMxMzRX16tVLa9eunfo+7tixQ12PgQMHFvl9PXz4sDZjxgz1PZXrKMfZrFkz7a677tJcxapVq1QN1RUrVqgaoSNHjlTXJCkpSX3+1FNPaZMnT7Ys//3332vu7u7a3LlzVU3ladOmqRrMe/fu1VyVo8co3+FNmzZpR44c0eLj47UBAwZo3t7e2v79+zVXlZaWZvmbk/Awb948NS5/l0KOT47T7OjRo5qvr682YcIEdR1jYmI0Nzc3LTY2VqtolT64SXVbuQi2BjO5Icj0tm3bLPPkxvfcc89pNWvWVBfn4YcftgqIrkiq9ds6zvzHJdNyTkRGRobWs2dPrU6dOurG0bhxY23EiBGWP0Y9HKO5OcCUKVO0oKAgdfORB51Dhw5prurixYsqmEnw9vf314YOHWoVvAt+X0+ePKkCWa1atdTxycOc3ExSUlI0V7JgwQL1wOjp6amqzf/4449WTRnk2ub36aefarfccotaXqqTb9iwQXN1jhzjiy++aFlWvpu9e/fWEhISNFe2bds2m39/5uOS/+U4C64TGhqqjlMeuvL/bVYk/uQNERHpjsvWliQiIiotBjciItIdBjciItIdBjciItIdBjciItIdBjciItIdBjciItIdBjciItIdBjciItIdBjciItIdBjciItIdBjciIoLe/D+0z3N0XdZmKAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 20\n",
    "rng = np.random.default_rng(42)\n",
    "x = rng.normal(size=n)\n",
    "X = x.reshape(-1, 1)\n",
    "y = x > 0\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(x, y, c=y)\n",
    "u = np.linspace(*plt.xlim(), 100)\n",
    "plt.plot([0, 0], [-0.1, 1.1], \"k--\")\n",
    "plt.title(\"Perfect separation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider fitting a logistic regression model **without intercept** to this dataset, i.e., minimizing\n",
    "$$\n",
    "L(c) = - \\frac1n\\sum_{i<n}\\left(y_i\\log\\sigma(c x_i) +  (1 - y_i)\\log(1 - \\sigma(c x_i))\\right).\n",
    "$$\n",
    "over numbers $c$.\n",
    "\n",
    "**To do:** Plot $L(c)$ versus $c$ for an evenly-spaced grid of 100 values between 0 and 20. What do you observe?\n",
    "\n",
    "Feel free to use Scikit-Learn's built-in log-loss function, `sklearn.metrics.log_loss`.\n",
    "\n",
    "The **sigmoid** or **expit** function $\\sigma$ is available through the Scipy package as `scipy.special.expit`. It's defined by\n",
    "$$\n",
    "\\sigma(u) = \\frac1{1 + e^{-u}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since\n",
    "$$\n",
    "y_i = 0\\Longleftrightarrow x_i < 0\\quad\\text{and}\n",
    "y_i = 1\\Longleftrightarrow x_i > 0,\n",
    "$$\n",
    "we have\n",
    "$$\n",
    "L(c) = -\\frac1n\\left\\{\\sum_{i\\,:\\,x_i > 0} \\log\\sigma(cx_i) + \\sum_{i\\,:\\,x_i < 0} \\log(1 - \\sigma(cx_i))\\right\\}\n",
    "$$\n",
    "\n",
    "**To do:** For each $i$ with $x_i > 0$ (resp., $x_i < 0$), plot $\\log\\sigma(cx_i)$ (resp. $\\log(1 - \\sigma(cx_i))$) versus $c$ on the left panel (resp., right panel) of the plot in the cell below. \n",
    "\n",
    "You should observe that each term in the sum for $L(c)$ decays to $0$ as $c\\to\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:** *Prove* that each term in the sum for $L(c)$ decays to $0$ as $c\\to\\infty$. Proceed as follows, using the definition of $\\sigma$ together with properties of exponentials and logarithms:\n",
    "\n",
    "- Explain why\n",
    "  $$\n",
    "  \\lim_{u\\to\\infty} \\log\\sigma(u) = 0.\n",
    "  $$\n",
    "\n",
    "- Conclude that if $x > 0$, then\n",
    "  $$\n",
    "  \\lim_{c\\to\\infty} \\log\\sigma(cx) = 0.\n",
    "  $$\n",
    "\n",
    "- Explain why\n",
    "  $$\n",
    "  \\lim_{u\\to-\\infty} \\log(1 - \\sigma(u)) = 0.\n",
    "  $$\n",
    "\n",
    "- Conclude that if $x < 0$, then\n",
    "  $$\n",
    "  \\lim_{c\\to\\infty} \\log(1 - \\sigma(cx)) = 0.\n",
    "  $$\n",
    "\n",
    "- Conclude that\n",
    "  $$\n",
    "  \\lim_{c\\to\\infty} L(c) = 0\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's return to the two-class iris dataset.\n",
    "\n",
    "Using Scikit-Learn's logistic regression, we extract a hyperplane $v_0\\cdot x = 0$ that separates class 0 from class 1 in 4-dimensional feature space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0 = [-1.26145424 -4.44578623  6.60584726  3.20483996]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris_01()\n",
    "\n",
    "model = LogisticRegression(penalty=None, fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "assert accuracy_score(y, model.predict(X)) == 1\n",
    "\n",
    "v0 = model.coef_.squeeze()\n",
    "print(f\"v0 = {v0}\")\n",
    "\n",
    "assert np.all(X[y == 0] @ v0 < 0)\n",
    "assert np.all(X[y == 1] @ v0 > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:** Plot $L(cv_0)$ versus $c$ for an evenly-spaced grid of 100 values between 0 and 1. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:** Prove that\n",
    "$$\n",
    "\\lim_{c\\to\\infty} L(cv_0) = 0.\n",
    "$$\n",
    "\n",
    "Hint: Reduce to the 1-dimensional case (analyzed above) by letting $z_i = v_0\\cdot x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try fitting a Bayesian logistic regression model to the two-class iris dataset using Bambi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Formula: label ~ sl + sw + pl + pw\n",
       "        Family: bernoulli\n",
       "          Link: p = logit\n",
       "  Observations: 100\n",
       "        Priors: \n",
       "    target = p\n",
       "        Common-level effects\n",
       "            Intercept ~ Normal(mu: 0.0, sigma: 1.5)\n",
       "            sl ~ Normal(mu: 0.0, sigma: 1.5662)\n",
       "            sw ~ Normal(mu: 0.0, sigma: 2.0993)\n",
       "            pl ~ Normal(mu: 0.0, sigma: 0.6933)\n",
       "            pw ~ Normal(mu: 0.0, sigma: 1.7783)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that label==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, sl, sw, pl, pw]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbdb06d1d0145fd971859687d4f7f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-5.103</td>\n",
       "      <td>6.650</td>\n",
       "      <td>-17.250</td>\n",
       "      <td>7.423</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.088</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>3186.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>1.424</td>\n",
       "      <td>1.212</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>3.855</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.017</td>\n",
       "      <td>3230.0</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sw</th>\n",
       "      <td>-2.705</td>\n",
       "      <td>1.338</td>\n",
       "      <td>-5.109</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.018</td>\n",
       "      <td>3202.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>1.205</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.098</td>\n",
       "      <td>2.274</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>2762.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pw</th>\n",
       "      <td>3.036</td>\n",
       "      <td>1.440</td>\n",
       "      <td>0.240</td>\n",
       "      <td>5.556</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.017</td>\n",
       "      <td>3497.0</td>\n",
       "      <td>2524.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  ...  mcse_sd  ess_bulk  ess_tail  r_hat\n",
       "Intercept -5.103  6.650 -17.250    7.423  ...    0.088    3810.0    3186.0    1.0\n",
       "sl         1.424  1.212  -0.700    3.855  ...    0.017    3230.0    2610.0    1.0\n",
       "sw        -2.705  1.338  -5.109   -0.101  ...    0.018    3202.0    2805.0    1.0\n",
       "pl         1.205  0.585   0.098    2.274  ...    0.008    3352.0    2762.0    1.0\n",
       "pw         3.036  1.440   0.240    5.556  ...    0.017    3497.0    2524.0    1.0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris_01()\n",
    "\n",
    "df = X.rename(\n",
    "    columns={\n",
    "        \"sepal length (cm)\": \"sl\",\n",
    "        \"sepal width (cm)\": \"sw\",\n",
    "        \"petal length (cm)\": \"pl\",\n",
    "        \"petal width (cm)\": \"pw\",\n",
    "    }\n",
    ")\n",
    "df[\"label\"] = y\n",
    "\n",
    "model = bmb.Model(\"label ~ sl + sw + pl + pw\", df, family=\"bernoulli\")\n",
    "display(model)\n",
    "fit = model.fit()\n",
    "az.summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard errors look ok, and accuracy score of 1.0.\n",
    "\n",
    "**To do:** Why didn't Bambi have an issue with the perfect separability like statsmodels did?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(fit, data=df)\n",
    "assert accuracy_score(df[\"label\"], fit.posterior[\"p\"].mean(axis=(0, 1)) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:** How small can you set the `sigma` parameter on the priors for the Bambi model before prediction accuracy starts to suffer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that label==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, sl, sw, pl, pw]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a3afd8f74347c3b13c99e6a23a9d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "sigma = 0.1\n",
    "\n",
    "priors = {\n",
    "    \"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=sigma),\n",
    "    \"sl\": bmb.Prior(\"Normal\", mu=0, sigma=sigma),\n",
    "    \"sw\": bmb.Prior(\"Normal\", mu=0, sigma=sigma),\n",
    "    \"pl\": bmb.Prior(\"Normal\", mu=0, sigma=sigma),\n",
    "    \"pw\": bmb.Prior(\"Normal\", mu=0, sigma=sigma),\n",
    "}\n",
    "\n",
    "model = bmb.Model(\"label ~ sl + sw + pl + pw\", df, family=\"bernoulli\", priors=priors)\n",
    "fit = model.fit()\n",
    "model.predict(fit, data=df)\n",
    "assert accuracy_score(df[\"label\"], fit.posterior[\"p\"].mean(axis=(0, 1)) > 0.5) == 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
